{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-09T16:56:03.933325Z",
          "start_time": "2023-11-09T16:56:00.517820Z"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "dataset_splits.csv not found in data_path.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m processed_path\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m forest_sat_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMineSATDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Iterate over all dataset indices\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(forest_sat_dataset)):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Get the filepaths for the current index\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/github/bc-wildfire-prediction/sat_log_file/dataset.py:53\u001b[0m, in \u001b[0;36mMineSATDataset.__init__\u001b[0;34m(self, split, data_path, transformations, preprocessing, flatten_mask, use_mask, rescale, min_max_normalization, max_values)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m=\u001b[39m split\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m ], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplit must be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_splits.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m )\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_splits.csv not found in data_path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_mask \u001b[38;5;241m=\u001b[39m use_mask\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale \u001b[38;5;241m=\u001b[39m rescale\n",
            "\u001b[0;31mAssertionError\u001b[0m: dataset_splits.csv not found in data_path."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "os.chdir('/Users/glenn_hyh/Documents/github/bc-wildfire-prediction')\n",
        "from sat_log_file import dataset\n",
        "import tifffile as tiff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# data_path = Path(os.getenv(\"prepare_dataset_folder\"))\n",
        "# processed_path = Path(os.getenv(\"processed_images_folder\"))\n",
        "data_path = Path('prepared_dataset')\n",
        "processed_path = Path('processed_images_folder')\n",
        "\n",
        "split = \"test\"  # Adjust as needed for 'val' or 'test'\n",
        "\n",
        "# Ensure the processed data folder exists\n",
        "processed_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Instantiate the dataset\n",
        "forest_sat_dataset = dataset.MineSATDataset(split=split, data_path=data_path)\n",
        "\n",
        "# Iterate over all dataset indices\n",
        "for index in range(len(forest_sat_dataset)):\n",
        "    # Get the filepaths for the current index\n",
        "    filepath = forest_sat_dataset.filepaths[index]\n",
        "\n",
        "    # Extract the original directory name\n",
        "    original_dir_name = Path(filepath).name\n",
        "\n",
        "    # Get the transformed images\n",
        "    images_dict = forest_sat_dataset.get_images(\n",
        "        index)  # Ensure you call the correct method\n",
        "\n",
        "    # Create a new directory path for the processed images\n",
        "    processed_dir_path = processed_path / original_dir_name\n",
        "    processed_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img_type, image in images_dict.items():\n",
        "        # Skip saving the mask if you only want the indices and RGB images\n",
        "        if img_type == \"Mask\":\n",
        "            continue\n",
        "\n",
        "        if img_type == \"NBR\":\n",
        "            # Apply color mapping for NBR\n",
        "            plt.imshow(image, cmap=plt.cm.RdYlGn, vmin=-1, vmax=1)\n",
        "            plt.colorbar(orientation='vertical')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Save the current figure to a numpy array\n",
        "            fig = plt.gcf()\n",
        "            plt.draw()\n",
        "            image_np = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "            image_np = image_np.reshape(\n",
        "                fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "            # Convert numpy array to PIL Image\n",
        "            pil_image = Image.fromarray(image_np)\n",
        "\n",
        "            # Define the filename, replacing .tif with .png for NBR\n",
        "            filename = f\"{img_type}.png\"\n",
        "\n",
        "            # Close the figure to free memory\n",
        "            plt.close(fig)\n",
        "        else:\n",
        "            # Normalize the image data to 0-255 for other image types\n",
        "            # Clip to the range you want\n",
        "            image = np.clip(image, 0, np.max(image))\n",
        "            image_8bit = ((image - np.min(image)) /\n",
        "                          (np.max(image) - np.min(image)) * 255).astype('uint8')\n",
        "\n",
        "            # If the image has more than one channel, convert it to RGB\n",
        "            if image_8bit.ndim > 2 and image_8bit.shape[2] > 3:\n",
        "                # Convert multi-band images (e.g., 4 bands) to RGB (3 bands) before saving as JPEG\n",
        "                image_8bit = image_8bit[:, :, :3]\n",
        "\n",
        "            # Create the PIL Image from the numpy array\n",
        "            pil_image = Image.fromarray(image_8bit)\n",
        "\n",
        "            # Define the filename, replacing .tif with .jpg for other image types\n",
        "            filename = f\"{img_type}.jpg\"\n",
        "\n",
        "        # Define the full path for the file\n",
        "        filepath = processed_dir_path / filename\n",
        "\n",
        "        # Save the image\n",
        "        pil_image.save(filepath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2f00d1e063ca7e",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neu-capstone-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
